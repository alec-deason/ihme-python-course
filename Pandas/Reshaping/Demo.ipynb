{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Reshaping\n",
    "\n",
    "Dataframes come in all different shapes and sizes,\n",
    "but typically when we work with them, we want them\n",
    "to be in the same shape so it is more uniform.\n",
    "\n",
    "This module is about reshaping pandas dataframes.\n",
    "There are lots of different methods, some of which\n",
    "are:\n",
    "\n",
    "1. pivot\n",
    "1. melt\n",
    "1. stack\n",
    "1. unstack\n",
    "\n",
    "There are also functions for combining different \n",
    "DataFrames, like\n",
    "\n",
    "1. concat\n",
    "2. merge\n",
    "3. join\n",
    "\n",
    "The methods listed above are only a small fraction\n",
    "of what is available in the Pandas API, and we might\n",
    "not be able to cover everything we listed.\n",
    "\n",
    "For documentation on all of the features provided by \n",
    "Pandas, check out:\n",
    "\n",
    "* https://pandas.pydata.org/pandas-docs/stable/reshaping.html\n",
    "* https://pandas.pydata.org/pandas-docs/stable/merging.html\n",
    "\n",
    "### Disclaimer:\n",
    "I'm a noob at this stuff. I just read docs and call functions\n",
    "until the things get in the right shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivoting\n",
    "Given two \"categorical\" columns and \"values\" column,\n",
    "``df.pivot`` generates a pivot table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data.csv\")\n",
    "query = (\n",
    "    \"location_id == 6 \"\n",
    "    \"and sex_id == 2\")\n",
    "\n",
    "# Two categorical columns, one values column.\n",
    "small_data = data.query(query)[\n",
    "    [\"age_group_id\", \"year_id\", \"mort_rate\"]]\n",
    "small_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data_pivot = small_data.pivot(\n",
    "    index=\"year_id\",\n",
    "    columns=\"age_group_id\",\n",
    "    values=\"mort_rate\")\n",
    "small_data_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data_pivot.reset_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data_pivot[5][1995]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data_pivot[[2,3]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data_pivot[2:5].head()  # this doesn't do what we expect!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to use pd.IndexSlice to propery slice the index.\n",
    "small_data_pivot.loc[pd.IndexSlice[:, 2:5]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melting, the opposite of pivoting, kind of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start from a dataframe without a hierarchical index on the columns\n",
    "flat_data = small_data_pivot.reset_index()\n",
    "flat_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_data = flat_data.melt(id_vars=\"year_id\", value_name=\"mort_rate\")\n",
    "long_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "small_data - long_data \n",
    "# this doesn't work because the index for long_data got reset\n",
    "# by pretty much everything we did, and pandas does operations\n",
    "# by aligning on the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just showing that the arrays didn't add properly.\n",
    "print(len(small_data))\n",
    "print(len(long_data))\n",
    "print(len(small_data) + len(long_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking and Unstacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_data = data.set_index([\"location_id\", \"age_group_id\", \"sex_id\", \"year_id\"])[[\"mort_rate\"]]\n",
    "indexed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unstack moves the `fastest-changing-row-index` to\n",
    "# the `fastest-changing-column-index`.\n",
    "indexed_data.unstack().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking will move the fastest changing column\n",
    "# index to the fastest changing row index.\n",
    "indexed_data.unstack().stack().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the column index isn't hierarchical, then it converts it into \n",
    "# one long series.\n",
    "print(type(indexed_data.unstack()[\"mort_rate\"].stack()))\n",
    "print(indexed_data.unstack()[\"mort_rate\"].stack().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We can convert this series back into a dataframe with the same index.\n",
    "pd.DataFrame(\n",
    "    indexed_data.unstack()[\"mort_rate\"].stack(), \n",
    "    columns=[\"mort_rate\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, stack and unstack don't work well when you don't have multi-indexes\n",
    "on the columns or rows (respectively)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining DataFrames\n",
    "Merging, concattenating, and joining.\n",
    "\n",
    "## Concat\n",
    "This is used for adding a bunch of new rows to a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a_few_rows = pd.DataFrame(dict(\n",
    "    x=[1,2,3,1,2,3],\n",
    "    y=[1,1,1,2,2,2],\n",
    "    val=np.random.rand(6)\n",
    "    ))\n",
    "a_few_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_more_rows = pd.DataFrame(dict(\n",
    "    x=[1,2,3,1,2,3],\n",
    "    y=[3,3,3,4,4,4],\n",
    "    val=np.random.rand(6)\n",
    "    ))\n",
    "some_more_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_data_set = pd.concat([a_few_rows, some_more_rows])\n",
    "long_data_set\n",
    "# Notice how weird the index is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yet_another_set_of_rows = pd.DataFrame(dict(\n",
    "    x=[1,2,3,1,2,3],\n",
    "    y=[12,12,12,-12,-12,-12],\n",
    "    val=100\n",
    "    ))\n",
    "yet_another_set_of_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_data_set + yet_another_set_of_rows  # weird arithemetic because the index is weird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When concatenating dataframes, there are two ways to do it:\n",
    "```\n",
    "result = pd.DataFrame()\n",
    "for path in filenames:\n",
    "    df = pd.read_csv(path)\n",
    "    result = pd.concat([result, df])\n",
    "```\n",
    "and\n",
    "```\n",
    "dataframes = []\n",
    "for path in filenames:\n",
    "    df = pd.read_csv(path)\n",
    "    dataframes.append(df)\n",
    "result = pd.concat(dataframes)\n",
    "```\n",
    "\n",
    "One way is super bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_names = pd.DataFrame(dict(\n",
    "    x=[1,2,3],\n",
    "    names=[\"Kendrick\", \"Ken\", \"K-Dot\"]\n",
    "    ))\n",
    "x_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "long_data_set.merge(x_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WOW THAT WAS EASY\n",
    "\n",
    "Other things:\n",
    "* left vs right vs inner vs outer merges\n",
    "* duplicate column names that aren't used for the merge get weird suffixes.\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge()  # check out the merge api with a shift-tab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JOINING\n",
    "This is like merging, but doesn't work.\n",
    "\n",
    "That's a joke. Join is used to join on the index, as opposed to values in a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = [\"location_id\", \"age_group_id\", \"sex_id\", \"year_id\"]\n",
    "mort_rates = data.set_index(index)[[\"mort_rate\"]]\n",
    "pops = data.set_index(index)[[\"population\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mort_rates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pops.join(mort_rates).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECRETS:\n",
    "data prep for the exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mort_pop_data = pd.read_csv(\"../data.csv\")\n",
    "mort_pop_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mort_only = mort_pop_data[[\"location_id\", \"age_group_id\", \"sex_id\", \"year_id\", \"mort_rate\"]]\n",
    "pop_only = mort_pop_data[[\"location_id\", \"age_group_id\", \"sex_id\", \"year_id\", \"population\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mort_wide = mort_only.set_index(\n",
    "        [\"location_id\", \"age_group_id\", \"sex_id\", \"year_id\"]\n",
    "    ).unstack()[\"mort_rate\"]\n",
    "logged_mort_wide = np.log(mort_wide).reset_index()\n",
    "logged_mort_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_wide = pop_only.set_index(\n",
    "        [\"location_id\", \"sex_id\", \"year_id\", \"age_group_id\"]\n",
    "    ).unstack()[\"population\"].reset_index().set_index([\"location_id\", \"sex_id\", \"year_id\"]).sort_index()\n",
    "pop_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logged_mort_wide.to_csv(\"mort.csv\")\n",
    "pop_wide.to_hdf(\"pop.hdf\", \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def deaths_and_death_rates_and_pops():\n",
    "    \"\"\"\n",
    "    Returns number of deaths for all locations, ages, sexes, and years,\n",
    "    along with mort_rate and population.\n",
    "    \n",
    "    number of deaths = mortality_rate * population\n",
    "    \n",
    "    The two files are provided, but they have different formats, and\n",
    "    mortality is in log rate space. Use jupyter to explore the data \n",
    "    within each file and how you can reshape the files and compute \n",
    "    number of deaths.\n",
    "    \n",
    "    Make sure you convert the log mortality rates into mortality rates!\n",
    "    \n",
    "    Return:\n",
    "        pd.DataFrame: a dataframe with columns location_id, sex_id,\n",
    "            year_id, age_group_id, mort_rate, population, and num_deaths;\n",
    "            and a simple index (just 0 to N).\n",
    "    \"\"\"\n",
    "    log_mort_file = \"mort.csv\"\n",
    "    pop_file = \"pop.hdf\"\n",
    "\n",
    "    # Reshaping pops\n",
    "    pop_wide = pd.read_hdf(pop_file)\n",
    "    pop_long = pd.DataFrame(pop_wide.stack(), columns=[\"population\"]).reset_index()\n",
    "\n",
    "    # Reshaping log_mort\n",
    "    mort_wide = pd.read_csv(log_mort_file).drop(\"Unnamed: 0\", axis=1)\n",
    "    mort_long = mort_wide.melt(\n",
    "        id_vars=[\"location_id\", \"age_group_id\", \"sex_id\"], \n",
    "        value_name=\"log_mort_rate\",\n",
    "        var_name=\"year_id\",\n",
    "        )\n",
    "    mort_long[\"year_id\"] = mort_long[\"year_id\"].astype(\"int\")\n",
    "    \n",
    "    # Converting from log to linear space.\n",
    "    mort_long[\"mort_rate\"] = np.exp(mort_long[\"log_mort_rate\"])\n",
    "    mort_long.drop(\"log_mort_rate\", axis=1, inplace=True)\n",
    "    \n",
    "    data = mort_long.merge(pop_long)\n",
    "    data[\"num_deaths\"] = data[\"mort_rate\"] * data[\"population\"]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_deaths_and_death_rates_and_pops():\n",
    "    res = deaths_and_death_rates_and_pops()\n",
    "    assert set(res.columns) == set([\n",
    "        \"location_id\", \"sex_id\", \"year_id\", \"age_group_id\", \n",
    "        \"mort_rate\", \"population\", \"num_deaths\"]), \"Missing columns.\"\n",
    "    \n",
    "    assert len(res) == 51480, len(res)\n",
    "    \n",
    "    one_set_of_vals = res.query(\n",
    "            \"location_id == 34 \"\n",
    "            \"and age_group_id == 19 \"\n",
    "            \"and sex_id == 2 \"\n",
    "            \"and year_id == 2009\"\n",
    "        )[[\"mort_rate\", \"population\", \"num_deaths\"]].values\n",
    "    \n",
    "    expected_vals = [0.045623, 112054.0, 5112.225765]\n",
    "    \n",
    "    assert np.isclose(one_set_of_vals, expected_vals).all()\n",
    "\n",
    "test_deaths_and_death_rates_and_pops()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
