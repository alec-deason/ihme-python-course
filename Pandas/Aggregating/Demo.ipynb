{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Pandas Advanced Operations\n",
    "\n",
    "We're going to cover groupby, aggregate, transform, apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_example = pd.DataFrame(dict(\n",
    "    family=[\"Tang\", \"Tang\", \n",
    "           \"Not Tang\", \"Not Tang\", \"Not Tang\",\n",
    "           \"Carroll\", \"Carroll\", \"Carroll\"],\n",
    "    name=[\"Kendrick\", \"Terence\", \n",
    "          \"Tonia\", \"Lawrence\", \"Ying\", \n",
    "          \"Alice\", \"The Frumious Bandersnatch\", \"The Jabberwock\"],\n",
    "    weight=[130, 150,\n",
    "            135, 175, 125,\n",
    "            100, 5000, 99999]\n",
    "))\n",
    "simple_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A weird question\n",
    "How much does each family weigh?\n",
    "\n",
    "Solution using what we already know:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "families = simple_example[\"family\"].unique()\n",
    "for family in families:\n",
    "    subset = simple_example.query(\"family == @family\")\n",
    "    summed_weight = subset[\"weight\"].sum()\n",
    "    print(\"The {family} Family weighs {weight} pounds. WOW!\".format(\n",
    "        family=family, weight=summed_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O frabjous day! Callooh! Callay!\n",
    "\n",
    "How can we do this in a more effective way using the great\n",
    "tools Pandas provides?\n",
    "\n",
    "Answer: **groupby**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution using pandas **groupby**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group, family in simple_example.groupby(\"family\"):\n",
    "    print(group)\n",
    "    print(family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for family, group in simple_example.groupby(\"family\"):\n",
    "    summed_weight = group[\"weight\"].sum()\n",
    "    print(\"The {family} Family weighs {weight} pounds. WOW!\".format(\n",
    "        family=family, weight=summed_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using groupby in an even better way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = simple_example.groupby(\"family\")[\"weight\"].sum()\n",
    "for family in weights.index:\n",
    "    summed_weight = weights[family]\n",
    "    print(\"The {family} Family weighs {weight} pounds. WOW!\".format(\n",
    "        family=family, weight=summed_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A more realistic question:\n",
    "In 2010, how many male deaths were there in countries larger than Japan (in population?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A solution without groupby\n",
    "I'm going to go through this really fast, so please bear with me. If you want me to go slower, just yell at me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def male_deaths_in_big_locations():\n",
    "    \"\"\"\n",
    "    For 2010, return a dictionary mapping location_id to total \n",
    "    number of male deaths for locations with populations greater than\n",
    "    the population of the united states.\n",
    "    \n",
    "    Things you need to know:\n",
    "    * males is sex_id 1.\n",
    "    * united states is location_id 102.\n",
    "    * death numbers = mort_rate * population\n",
    "    \n",
    "    The data set is provided within the function.\n",
    "\n",
    "    Return:\n",
    "        dict[int: int]\n",
    "    \n",
    "    \"\"\"\n",
    "    data = pd.read_csv(\"../data.csv\")\n",
    "    \n",
    "    male_data_2010 = data.query(\n",
    "        \"year_id == 2010 and sex_id == 1\")\n",
    "    male_data_2010[\"mort_count\"] = (\n",
    "        male_data_2010[\"mort_rate\"]\n",
    "        * male_data_2010[\"population\"]\n",
    "        )\n",
    "    us_pop = get_pop(male_data_2010, 102)\n",
    "    \n",
    "    locations = male_data_2010[\"location_id\"].unique()\n",
    "    result = {}\n",
    "    for location_id in locations:\n",
    "        pop = get_pop(male_data_2010, location_id)\n",
    "        if pop > us_pop:\n",
    "            result[location_id] = get_mort_count(\n",
    "                male_data_2010, location_id)\n",
    "        else:\n",
    "            pass\n",
    "    return result\n",
    "    \n",
    "    \n",
    "def get_pop(male_data_2010, location_id):\n",
    "    pop = male_data_2010.query(\n",
    "            \"location_id == @location_id\"\n",
    "        ).sum()[\"population\"]\n",
    "    return pop\n",
    "\n",
    "    \n",
    "def get_mort_count(male_data_2010, location_id):\n",
    "    mort_count = male_data_2010.query(\n",
    "            \"location_id == @location_id\"\n",
    "        ).sum()[\"mort_count\"]\n",
    "    return mort_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_male_deaths_in_big_locations():\n",
    "    res = male_deaths_in_big_locations()\n",
    "    \n",
    "    assert len(res) == 2, \"not the right size.\"\n",
    "    assert res[6] == 5484711.4546094909\n",
    "    assert res[163] == 5231218.5870856401\n",
    "    assert 102 not in res, \"I said bigger than america, not bigger than or equal to.\"\n",
    "    \n",
    "test_male_deaths_in_big_locations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A solution with groupby\n",
    "I want to go through this really slowly, so if I'm going too fast please tell me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data.csv\")\n",
    "data[\"mort_count\"] = (\n",
    "        data[\"mort_rate\"] * data[\"population\"])\n",
    "\n",
    "male_data_2010 = data.query(\n",
    "    \"year_id == 2010 and sex_id == 1\")\n",
    "male_data_2010[\"mort_count\"] = (\n",
    "        male_data_2010[\"mort_rate\"]\n",
    "        * male_data_2010[\"population\"]\n",
    "        )\n",
    "male_data_2010.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pops_and_mort_count = male_data_2010.groupby(\n",
    "        \"location_id\"\n",
    "    )[\n",
    "        [\"population\", \"mort_count\"]\n",
    "    ].sum()\n",
    "pops_and_mort_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "us_pop = pops_and_mort_count.loc[102][\"population\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "big_mort_counts = pops_and_mort_count.query(\"population > @us_pop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_mort_counts[\"mort_count\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def another_male_deaths_in_big_locations():\n",
    "    \"\"\"\n",
    "    For 2010, return a dictionary mapping location_id to total \n",
    "    number of male deaths for locations with populations greater than\n",
    "    the population of the united states.\n",
    "    \n",
    "    Things you need to know:\n",
    "    * males is sex_id 1.\n",
    "    * united states is location_id 102.\n",
    "    * death numbers = mort_rate * population\n",
    "    \n",
    "    The data set is provided within the function.\n",
    "\n",
    "    Return:\n",
    "        dict[int: int]\n",
    "    \n",
    "    \"\"\"\n",
    "    data = pd.read_csv(\"../data.csv\")\n",
    "\n",
    "    male_data_2010 = data.query(\n",
    "        \"year_id == 2010 and sex_id == 1\")\n",
    "    male_data_2010[\"mort_count\"] = (\n",
    "            male_data_2010[\"mort_rate\"]\n",
    "            * male_data_2010[\"population\"]\n",
    "            )\n",
    "    \n",
    "    pops_and_mort_count = male_data_2010.groupby(\n",
    "            \"location_id\"\n",
    "        )[\n",
    "            [\"population\", \"mort_count\"]\n",
    "        ].sum()\n",
    "    us_pop = pops_and_mort_count.loc[102][\"population\"]\n",
    "    big_mort_counts = pops_and_mort_count.query(\"population > @us_pop\")\n",
    "    return big_mort_counts[\"mort_count\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_another_male_deaths_in_big_locations():\n",
    "    res = another_male_deaths_in_big_locations()\n",
    "    \n",
    "    assert len(res) == 2, \"not the right size.\"\n",
    "    assert res[6] == 5484711.4546094909\n",
    "    assert res[163] == 5231218.5870856401\n",
    "    assert 102 not in res, \"I said bigger than america, not bigger than or equal to.\"\n",
    "    \n",
    "test_another_male_deaths_in_big_locations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More group by\n",
    "\n",
    "**question**: what does the result represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(\n",
    "        [\"sex_id\", \"location_id\", \"year_id\"]\n",
    "    )[[\"mort_count\"]].sum().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**question**\n",
    "For each location and year, compute the average number of death per sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(\n",
    "        [\"year_id\", \"location_id\", \"age_group_id\"]\n",
    "    ).mean(\n",
    "    ).groupby(\n",
    "        [\"year_id\", \"location_id\"]\n",
    "    ).sum(\n",
    "    )[\n",
    "        [\"mort_count\"]\n",
    "    ].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Even more groupby\n",
    "groupby can be used in more flexible ways, too.\n",
    "\n",
    "### list\n",
    "Pass in a list like [1,1,0,0,1,0,0,0,1] to group \n",
    "a dataframe into two groups (a 0 group and a 1 group).\n",
    "\n",
    "### function\n",
    "Pass in a partitioning function where the rows are\n",
    "grouped by the value ``function(row)``.\n",
    "\n",
    "### probably a few other ways\n",
    "Read the docs. Here's a good place to start https://pandas.pydata.org/pandas-docs/stable/groupby.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregation\n",
    "Another way to do things like `data.sum` or `data.mean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.agg(\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.agg([\"sum\", \"mean\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform\n",
    "Transform allows you to apply a 1-to-1 function\n",
    "on all of the values in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.transform(np.sqrt).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_negative(x):\n",
    "    return -x\n",
    "\n",
    "data.transform(make_negative).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply\n",
    "Apply is like agg, but with functions you can pass in,\n",
    "as opposed to strings.\n",
    "\n",
    "This has a weird side effect, so you should avoid this\n",
    "if you can.\n",
    "\n",
    "**side effect**: In the current implementation apply calls func twice on the first column/row to decide whether it can take a fast or slow code path. This can lead to unexpected behavior if func has side-effects, as they will take effect twice for the first column/row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.apply(np.sqrt).head()  # it knows this is a 1-to-1 function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.apply(np.sum, axis=0)  # it knows this is a \"reduce\" operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is going to take a long long time\n",
    "# does anyone know why?\n",
    "\n",
    "data.apply(np.sum, axis=1).head()  # it knows this is a \"reduce\" operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECRETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# population formatting\n",
    "data = pd.read_csv(\"../data.csv\")\n",
    "pop_data = data[index + [\"population\"]]\n",
    "pop_data.to_csv(\"07_pop.csv\", index=False)\n",
    "pop_data.head()\n",
    "\n",
    "# the comm, inj, and ncd csvs were made willy nilly by kendrick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def big_aggregate():\n",
    "    \"\"\"Return the all cause global all-age both-sex draw level death counts.\n",
    "    \n",
    "    You're given three files containing the log mortality rates for _ncd, _comm,\n",
    "    and _inj causes. These files contain the data for:\n",
    "        * region-level locations\n",
    "        * non-aggregate age groups\n",
    "        * male and females\n",
    "        * gbd years\n",
    "        \n",
    "    The data provided contains draws.\n",
    "    \n",
    "    Return the draw-level death counts for the all-cause global all-age \n",
    "    both-sex aggregate for gbd years.\n",
    "    \n",
    "    Return:\n",
    "        pd.DataFrame: dataframe containing the big aggregate.\n",
    "    \"\"\"\n",
    "\n",
    "    # FILE NAMES! Don't change these.\n",
    "    pop_file = \"07_pop.csv\"\n",
    "    injury_file = \"07_inj.csv\"\n",
    "    communicable_file = \"07_comm.csv\"\n",
    "    ncd_file = \"07_ncd.csv\"\n",
    "\n",
    "    # Open the files\n",
    "    inj = pd.read_csv(injury_file)\n",
    "    comm = pd.read_csv(communicable_file)\n",
    "    ncd = pd.read_csv(ncd_file)\n",
    "    pop = pd.read_csv(pop_file)\n",
    "\n",
    "    # Add the three things together\n",
    "    index = [\"location_id\", \"age_group_id\", \"sex_id\", \"year_id\"]\n",
    "    comm_indexed = comm.set_index(index).transform(np.exp)\n",
    "    ncd_indexed = ncd.set_index(index).transform(np.exp)\n",
    "    inj_indexed = inj.set_index(index).transform(np.exp)\n",
    "    all_indexed = comm_indexed + ncd_indexed + inj_indexed\n",
    "    \n",
    "    # Join population and multiply to get death counts\n",
    "    pop_indexed = pop.set_index(index)\n",
    "    combined_data = all_indexed.join(pop_indexed)\n",
    "    draw_cols = [\"draw_{}\".format(i) for i in range(1000)]\n",
    "    combined_data[draw_cols] = combined_data[draw_cols].multiply(combined_data[\"population\"], axis=\"index\")\n",
    "\n",
    "    # Aggregate everything together by year.\n",
    "    return combined_data.groupby(\"year_id\")[draw_cols].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_big_aggregate():\n",
    "    res = big_aggregate()\n",
    "    \n",
    "    index = [\"location_id\", \"age_group_id\", \"sex_id\", \"year_id\"]\n",
    "    pop = pd.read_csv(\"07_pop.csv\").set_index(index)\n",
    "    _all = pd.read_csv(\"07_all.csv\").set_index(index).transform(np.exp)\n",
    "    big_data = _all.join(pop)\n",
    "    draw_cols = [\"draw_{}\".format(i) for i in range(1000)]\n",
    "    big_data[draw_cols] = big_data[draw_cols].multiply(big_data[\"population\"], axis=\"index\")\n",
    "    expected = big_data.drop(\"population\", axis=1).groupby(\"year_id\").sum()\n",
    "    expected.to_csv(\"07_expected.csv\")\n",
    "    \n",
    "    assert np.isclose(res, expected).all().all()\n",
    "    \n",
    "test_big_aggregate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
