{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Pandas IO (a subset)\n",
    "* read_*\n",
    "* to_*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'read_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b8fa7a4c1fc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'read_'"
     ]
    }
   ],
   "source": [
    "pd.read_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.to_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_tiny_df = pd.DataFrame([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "super_tiny_df.to_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSVs\n",
    "Lots of data files will be in csv format.\n",
    "This is one of the most common data formats out there,\n",
    "and thankfully, pandas can read them very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSVs in the terminal\n",
    "\n",
    "\n",
    "Before exploring CSVs with Pandas, check it out\n",
    "in the command line. \n",
    "\n",
    "You can open a terminal through jupyter (maybe not in Windows).\n",
    "\n",
    "Useful simple commands:\n",
    "* head\n",
    "* tail\n",
    "* less"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSVs in pandas\n",
    "\n",
    "Most of the read_* functions in pandas have tons of \n",
    "optional arguments for handling all sorts of different\n",
    "formats you might run into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The jupyter docs are too crowded\n",
    "go here instead\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful arguments:\n",
    "* sep and delimiter\n",
    "* header\n",
    "* names\n",
    "* index_col\n",
    "\n",
    "There are so many. If you want to open a CSV in pandas and\n",
    "the formatting is presenting problems, definitely check the\n",
    "built-in functionality before reformatting stuff on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"../data.csv\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"../data.csv\", header=None).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "really_awful_dataframe = pd.read_csv(\n",
    "    \"../data.csv\", \n",
    "    names=[\"locs\", \"ages\", \"sexes\", \"years\", \"mort\", \"pop\"],\n",
    "    skiprows=1,\n",
    "    dtype={\"pop\": \"str\"}\n",
    "    ).head()\n",
    "really_awful_dataframe[\"pop\"][0]\n",
    "type(really_awful_dataframe[\"pop\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\n",
    "    \"../data.csv\",\n",
    "    header=None,\n",
    "    skiprows=1,\n",
    "    names=[\"location_id\", \"age_group_id\", \"sex_id\", \"year_id\", \"a\", \"b\"],\n",
    "    dtype=\"float\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\n",
    "    \"../data.csv\",\n",
    "    index_col=[\"location_id\", \"age_group_id\", \"sex_id\", \"year_id\"],\n",
    "    dtype=\"float\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another order for the index.\n",
    "pd.read_csv(\n",
    "    \"../data.csv\",\n",
    "    index_col=[\"year_id\", \"location_id\", \"age_group_id\", \"sex_id\"],\n",
    "    dtype=\"float\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date time formatting!\n",
    "Date and date formatting is so prevelant and\n",
    "annoying, pandas helps you parse them.\n",
    "\n",
    "Dates in a CSV are strings because everything\n",
    "in a CSV is a string. Sometimes we have a\n",
    "\"DD-MM-YYYY\" format, or sometimes \"DDMMYYY\",\n",
    "or \"YYYYMMDD\", or sometimes it is really awful like\n",
    "\"YYYY----MM----!!!@@@DD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"05_datetime.csv\")[\"date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"05_datetime.csv\", parse_dates=[\"date\"])[\"date\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crazy_date_data = pd.read_csv(\n",
    "    \"05_datetime.csv\", \n",
    "    parse_dates=[\"crazy_date\"])\n",
    "crazy_date_data[\"crazy_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.to_datetime(\n",
    "    crazy_date_data[\"crazy_date\"],\n",
    "    format=\"%Y----%M----!!!@@@%d\"\n",
    ")\n",
    "# There's a typo here! (%M isn't months...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Floating point precision problems\n",
    "Most problems related to CSVs comes down\n",
    "to everything being stored as strings.\n",
    "\n",
    "e.g. instead of storing dates as Date objects,\n",
    "they are stored as strings, which we need to parse.\n",
    "\n",
    "Similarly, floating point numbers are stored\n",
    "as strings with a limited number of characters.\n",
    "This introduces inefficiencies in memory and a loss\n",
    "of precision.\n",
    "\n",
    "#### Memory inefficiency\n",
    "We can store a single digit as a string in a single byte.\n",
    "A floating point number is 32 or 64 bits, which is\n",
    "4 or 8 bytes.\n",
    "\n",
    "\n",
    "One ascii character is 1 byte, while more complicated\n",
    "character encodings take several bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a floating point, this is 64 bits (8 bytes)\n",
    "floating_point = float(123 ** 2.3 / 1230001280001.128313)\n",
    "str_floating_point = str(floating_point)\n",
    "print(\"The string is {} bytes.\".format(\n",
    "    len(str_floating_point)))\n",
    "print(\"A floating point is 4 or 8 bytes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss of precision\n",
    "Floating points are weird. They're great for really big numbers\n",
    "or really tiny numbers. They're awful if we want to represent\n",
    "a large number with really high precision, e.g.\n",
    "1000000000.0000000000000001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to lose precision.\n",
    "1000000000.000000000011111111"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strings are even worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "N = 1000000\n",
    "\n",
    "small_value = np.random.rand(N) / 100000000.\n",
    "df = pd.DataFrame(dict(\n",
    "    big_value=100+small_value,\n",
    "    small_value=small_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"small_value\"].min())\n",
    "print(\"%1.30f\" % df[\"big_value\"].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"05_data.csv\")\n",
    "csv = pd.read_csv(\"05_data.csv\")\n",
    "\n",
    "print(csv[\"small_value\"].min())\n",
    "print(\"%1.30f\" % csv[\"big_value\"].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducing: HDF. \n",
    "* No further loss of precision! \n",
    "* Smaller file sizes! \n",
    "* Kaloo-kalay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_hdf(\"05_data.hdf\", \"data\")\n",
    "hdf = pd.read_hdf(\"05_data.hdf\")\n",
    "print(hdf[\"small_value\"].min())\n",
    "print(\"%1.30f\" % hdf[\"big_value\"].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -l  # look at how small it is on disk!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDFs\n",
    "\n",
    "HDF stands for Hierarchical Data Format.\n",
    "You can do stuff with the h5py package to directly manipulate \n",
    "HDF files, but pandas has built-in functions to read\n",
    "and write HDF.\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_hdf.html\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_hdf.html\n",
    "\n",
    "There are two formats:\n",
    "1. fixed\n",
    "2. table (to be used with ``data_columns``)\n",
    "\n",
    "They are useful for different scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code used to generate exercise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "EPSILON = 1e-4\n",
    "\n",
    "HDF_FILE_1 = \"05_forecast_1.hdf\"\n",
    "HDF_FILE_2 = \"05_forecast_2.hdf\"\n",
    "CSV_FILE_1 = \"05_observed_1.csv\"\n",
    "CSV_FILE_2 = \"05_observed_2.hdf\"\n",
    "\n",
    "observed = pd.DataFrame(dict(\n",
    "    person=[1, 2, 3] * 6,\n",
    "    date=([1] * 3 + [2] * 3 + [3] * 3) * 2,\n",
    "    foot=[\"L\"] * 9 + [\"R\"] * 9,\n",
    "    val=np.random.rand(18)\n",
    "    ))\n",
    "observed.to_csv(CSV_FILE_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "observed2 = pd.DataFrame(dict(\n",
    "    person=[1, 2, 3] * 6,\n",
    "    date=([1] * 3 + [2] * 3 + [3] * 3) * 2,\n",
    "    foot=[\"L\"] * 9 + [\"R\"] * 9,\n",
    "    val=np.random.rand(18) + 0.9\n",
    "    ))\n",
    "observed2.to_csv(CSV_FILE_2, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = pd.DataFrame(dict(\n",
    "    person=[1, 2, 3] * 6,\n",
    "    date=([1] * 3 + [2] * 3 + [3] * 3) * 2,\n",
    "    foot=[\"L\"] * 9 + [\"R\"] * 9,\n",
    "    val=np.random.rand(18)\n",
    "    ))\n",
    "\n",
    "predicted.set_index([\"date\", \"foot\"]).sort_index().to_hdf(\n",
    "    HDF_FILE_1, \"data\")\n",
    "predicted.set_index([\"person\", \"foot\", \"date\"]).sort_index().to_hdf(\n",
    "    HDF_FILE_2, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [\"date\", \"foot\", \"person\"]\n",
    "print(\n",
    "    (\n",
    "        (\n",
    "            (\n",
    "                observed2.set_index(index) - predicted.set_index(index)\n",
    "            ) ** 2\n",
    "        ).sum() / len(observed) \n",
    "    ) ** 0.5)\n",
    "print(\n",
    "    (\n",
    "        (\n",
    "            (\n",
    "                observed.set_index(index) - predicted.set_index(index)\n",
    "            ) ** 2\n",
    "        ).sum() / len(observed) \n",
    "    ) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# My solution\n",
    "\n",
    "def RMSE(hdf_file, csv_file):\n",
    "    \"\"\"Compute the RMSE of two timeseries stored in different formats.\n",
    "    \n",
    "    There is a model which writes its output as a HDF,\n",
    "    and the observed data is saved as a CSV. Compute \n",
    "    the root mean squared error (RMSE) of the model \n",
    "    compared to the observed data.\n",
    "    \n",
    "    RMSE equation in LaTeX:\n",
    "        \\sqrt{[\\sum_{i} (y_i - yhat_i) ^ 2] / 2}\n",
    "        \n",
    "    I'll write this on the board if someone needs it.\n",
    "    \n",
    "    The data looks something like this, but use Jupyter\n",
    "    to explore the different files and their formats.\n",
    "    \n",
    "         date    foot    person    val\n",
    "    0    1       L       1         0.356222\n",
    "    1    1       L       2         0.395130\n",
    "    2    1       L       3         0.180450\n",
    "    3    2       L       1         0.192698\n",
    "    4    2       L       2         0.363159\n",
    "    \n",
    "    Args:\n",
    "        hdf_file: predicted data in an hdf file.\n",
    "        csv_file: observed data in a csv file.\n",
    "    Returns:\n",
    "        float: the RMSE.\n",
    "    \"\"\"\n",
    "    index = [\"date\", \"foot\", \"person\"]\n",
    "        \n",
    "    csv = pd.read_csv(csv_file, index_col=index)[[\"val\"]]\n",
    "    hdf = pd.read_hdf(hdf_file).reset_index().set_index(index)\n",
    "    \n",
    "    return (\n",
    "        (\n",
    "            (\n",
    "                (\n",
    "                    csv - hdf\n",
    "                ) ** 2\n",
    "            ).sum() / len(csv) \n",
    "        ) ** 0.5)\n",
    "    \n",
    "    \n",
    "    raise NotImplementedError(\"You should probably implement this.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to test your code.\n",
    "\n",
    "def test_RMSE():\n",
    "    res = RMSE(HDF_FILE_1, CSV_FILE_1)\n",
    "    assert math.fabs(res - 0.416369) < EPSILON, res\n",
    "    \n",
    "    res = RMSE(HDF_FILE_2, CSV_FILE_1)\n",
    "    assert math.fabs(res - 0.416369) < EPSILON, res \n",
    "    \n",
    "    res = RMSE(HDF_FILE_1, CSV_FILE_2)\n",
    "    assert math.fabs(res - 0.970608) < EPSILON, res\n",
    "    \n",
    "    res = RMSE(HDF_FILE_2, CSV_FILE_2)\n",
    "    assert math.fabs(res - 0.970608) < EPSILON, res\n",
    "\n",
    "test_RMSE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
